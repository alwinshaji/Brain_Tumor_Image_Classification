{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "bmKjuQ-FpsJ3",
        "-Kee-DAl2viO"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  **Brain Tumor MRI Image Classification**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - **Classification**\n",
        "##### **Contribution**    - **Individual**\n",
        "##### **Name              -** **Alwin Shaji**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project focuses on developing a deep learning-based system to classify brain MRI images into four categories: glioma, meningioma, pituitary tumor, and no tumor. The primary objective is to create an automated solution that can assist radiologists by reducing diagnostic time and improving efficiency. MRI scans often contain subtle variations that require significant expertise to interpret, and a model capable of accurately predicting tumor type can help streamline workflows, especially in resource-limited settings. By leveraging image preprocessing, data augmentation, and advanced CNN architectures, the system aims to handle variability in image quality and patient positioning.\n",
        "\n",
        "The planned approach involves building two types of models: a custom CNN to establish a baseline and a fine-tuned ResNet50 model for higher accuracy using transfer learning. Class imbalance will be addressed through class weights, and training will be monitored using early stopping, learning rate reduction, and checkpointing to prevent overfitting and optimize resource usage. Performance evaluation will include accuracy, precision, recall, F1 score, and confusion matrix analysis, ensuring that the model‚Äôs reliability is thoroughly assessed.\n",
        "\n",
        "Finally, explainability is a key part of the plan. Visualization tools such as Grad-CAM will be integrated to highlight regions influencing predictions, building trust in the model‚Äôs decision-making process. The best-performing model will be saved in .h5 format for future deployment, and an interactive demo using Streamlit is envisioned to showcase real-time predictions. This approach not only targets technical accuracy but also prioritizes usability, interpretability, and real-world relevance in medical imaging applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to develop a deep learning-based solution for classifying brain MRI images into multiple categories according to tumor type. It involves building a custom CNN model from scratch and enhancing performance through transfer learning using pretrained models. The project also includes deploying a user-friendly Streamlit web application to enable real-time tumor type predictions from uploaded MRI images.\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your uploaded ZIP file\n",
        "zip_path = '/content/drive/MyDrive/Tumor.zip'\n",
        "\n",
        "# Destination to unzip\n",
        "extract_path = '/content/tumor_data'\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Check folders\n",
        "os.listdir(extract_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Path to extracted dataset\n",
        "dataset_path = '/content/tumor_data/Tumour'\n",
        "\n",
        "# List everything in the dataset path\n",
        "all_items = os.listdir(dataset_path)\n",
        "print(\"All items in dataset:\", all_items)\n",
        "\n",
        "# Only keep folders (ignore files like README)\n",
        "categories = [item for item in all_items if os.path.isdir(os.path.join(dataset_path, item))]\n",
        "print(\"\\nValid category folders:\", categories)\n",
        "\n",
        "# Count number of images in each category folder\n",
        "for category in categories:\n",
        "    folder = os.path.join(dataset_path, category)\n",
        "    num_images = sum([len(files) for _, _, files in os.walk(folder)])\n",
        "    print(f\"{category}: {num_images} images\")\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image\n",
        "\n",
        "# Paths to data splits\n",
        "base_path = '/content/tumor_data/Tumour'\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "valid_path = os.path.join(base_path, 'valid')\n",
        "test_path  = os.path.join(base_path, 'test')\n",
        "\n",
        "# Count images function (unchanged)\n",
        "def count_images(folder_path):\n",
        "    total = 0\n",
        "    for class_folder in os.listdir(folder_path):\n",
        "        class_path = os.path.join(folder_path, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            total += len(os.listdir(class_path))\n",
        "    return total\n",
        "\n",
        "# Image counts\n",
        "num_train = count_images(train_path)\n",
        "num_valid = count_images(valid_path)\n",
        "num_test  = count_images(test_path)\n",
        "\n",
        "print(f\"üßæ Number of training images: {num_train}\")\n",
        "print(f\"üßæ Number of validation images: {num_valid}\")\n",
        "print(f\"üßæ Number of test images: {num_test}\")\n",
        "\n",
        "# Filter only class folders (ignore .csv file)\n",
        "class_names = sorted([f for f in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, f))])\n",
        "print(f\"\\nüìö Classes ({len(class_names)}): {class_names}\")\n",
        "\n",
        "# View sample image size from the first actual class folder\n",
        "first_class = class_names[0]\n",
        "first_img_path = os.path.join(train_path, first_class, os.listdir(os.path.join(train_path, first_class))[0])\n",
        "img = Image.open(first_img_path)\n",
        "print(f\"\\nüñº Sample image size: {img.size}\")\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def count_images_in_each_class(folder_path):\n",
        "    print(f\"üìÅ Folder: {folder_path}\")\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_path = os.path.join(folder_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_count = len(os.listdir(class_path))\n",
        "            print(f\"üîπ {class_name}: {image_count} images\")\n",
        "\n",
        "# Check training set\n",
        "count_images_in_each_class('/content/tumor_data/Tumour/train')\n",
        "\n",
        "# Check validation set\n",
        "count_images_in_each_class('/content/tumor_data/Tumour/valid')\n",
        "\n",
        "# Check test set\n",
        "count_images_in_each_class('/content/tumor_data/Tumour/test')\n"
      ],
      "metadata": {
        "id": "Rf886BzV9_Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is organized into three main folders: train, valid, and test, each containing subfolders for the four classes ‚Äî glioma, meningioma, no_tumor, and pituitary. There are 1695 training images, 502 validation images, and 246 test images. The images are MRI scans with a sample resolution of 640√ó640 pixels. Since the dataset is already pre-split and well-structured by folder names, no manual label handling or data splitting is required. We'll resize the images during preprocessing to make them suitable for CNN input.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Images***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each sample in the dataset is a brain MRI image stored in JPEG or PNG format. The average resolution is 640√ó640 pixels. Images are grayscale or RGB scans taken from different angles and positions. The four classes ‚Äî glioma, meningioma, pituitary, and no_tumor ‚Äî correspond to visual patterns in the brain indicating the presence or absence of tumors. These differences may appear as irregular shapes, dense masses, or abnormal textures in specific regions. Understanding these patterns is key for the CNN model to learn how to classify the images accurately."
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no traditional data wrangling step required since the dataset is already clean and organized. The images are sorted into folders representing their respective classes. Instead of wrangling, we'll focus on preparing the images using preprocessing techniques such as resizing, normalization, and augmentation to make them suitable for deep learning models.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Make plots a little cleaner\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set(font_scale=1.0)\n",
        "\n",
        "# Paths\n",
        "BASE_DIR   = '/content/tumor_data/Tumour'\n",
        "TRAIN_DIR  = os.path.join(BASE_DIR, 'train')\n",
        "VALID_DIR  = os.path.join(BASE_DIR, 'valid')\n",
        "TEST_DIR   = os.path.join(BASE_DIR, 'test')\n",
        "\n",
        "IMG_SIZE   = (224, 224)\n",
        "BATCH_SIZE = 32\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images_in_dir(dir_path):\n",
        "    counts = {}\n",
        "    for cls in sorted(os.listdir(dir_path)):\n",
        "        cls_path = os.path.join(dir_path, cls)\n",
        "        if os.path.isdir(cls_path):\n",
        "            counts[cls] = len(os.listdir(cls_path))\n",
        "    return counts\n",
        "\n",
        "train_counts = count_images_in_dir(TRAIN_DIR)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(train_counts.keys(), train_counts.values(), color='red')\n",
        "plt.title('Training Set Class Distribution')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Training counts:\", train_counts)\n"
      ],
      "metadata": {
        "id": "y1ZIdRYH9290"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar chart shows the number of images available for each brain tumor category in the training dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It helps identify class imbalance. For example, if the glioma class has significantly more samples than no_tumor, the model might become biased toward glioma predictions."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By spotting imbalance early, I applied class weighting during training to ensure fairness across classes, leading to more reliable diagnostic predictions."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_total = sum(count_images_in_dir(TRAIN_DIR).values())\n",
        "valid_total = sum(count_images_in_dir(VALID_DIR).values())\n",
        "test_total  = sum(count_images_in_dir(TEST_DIR).values())\n",
        "\n",
        "splits = ['Train', 'Valid', 'Test']\n",
        "vals   = [train_total, valid_total, test_total]\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.bar(splits, vals, color='green')\n",
        "plt.title('Dataset Split Sizes')\n",
        "plt.ylabel('Image Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train: {train_total}, Valid: {valid_total}, Test: {test_total}\")\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart visualizes how the dataset is divided into training, validation, and test sets."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It confirms whether the data split maintains a healthy balance for model training, validation tuning, and unbiased performance testing (e.g., 70-20-10 ratio)."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring a proper split avoids overfitting and guarantees reliable generalization in real-world tumor classification scenarios."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "\n",
        "def show_samples_per_class(root_dir, n_per_class=3, max_rows=3):\n",
        "    # Get class names\n",
        "    classes = [cls for cls in sorted(os.listdir(root_dir)) if os.path.isdir(os.path.join(root_dir, cls))]\n",
        "    if not classes:\n",
        "        print(\"No classes found in:\", root_dir)\n",
        "        return\n",
        "\n",
        "    # Limit rows to max_rows\n",
        "    classes = classes[:max_rows]\n",
        "\n",
        "    # Set figure size dynamically\n",
        "    plt.figure(figsize=(n_per_class * 3, max_rows * 3))\n",
        "    plt.suptitle(\"Sample Images from Each Class\", fontsize=16, fontweight='bold')\n",
        "\n",
        "    idx = 1\n",
        "    for row, cls in enumerate(classes):\n",
        "        cls_dir = os.path.join(root_dir, cls)\n",
        "        imgs = [os.path.join(cls_dir, f) for f in os.listdir(cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        if len(imgs) == 0:\n",
        "            continue\n",
        "\n",
        "        # Pick random samples for the class\n",
        "        samples = random.sample(imgs, min(n_per_class, len(imgs)))\n",
        "\n",
        "        for j, img_path in enumerate(samples):\n",
        "            img = Image.open(img_path)\n",
        "            plt.subplot(max_rows, n_per_class, idx)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Add heading above first image of the row\n",
        "            if j == 0:\n",
        "                plt.ylabel(cls, fontsize=12, fontweight='bold', rotation=0, labelpad=30)\n",
        "\n",
        "            idx += 1\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust to make space for title\n",
        "    plt.show()\n",
        "\n",
        "# ‚úÖ Example usage:\n",
        "TRAIN_DIR = '/content/tumor_data/Tumour/train'\n",
        "show_samples_per_class(TRAIN_DIR, n_per_class=3, max_rows=3)\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar chart shows the number of images available for each tumor class (Glioma, Meningioma, Pituitary, No Tumor) in the dataset."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It highlights any class imbalance, which can negatively impact model performance by biasing predictions toward majority classes."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecting imbalance early allows corrective measures like class weighting or augmentation, improving diagnostic accuracy across all tumor types.\n",
        "\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a small augmentation generator (match training settings)\n",
        "aug_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.15,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Grab a batch\n",
        "preview_gen = aug_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Take one image and show augmented variants\n",
        "x_batch, y_batch = next(preview_gen)\n",
        "img = x_batch[0]\n",
        "\n",
        "n_aug = 6\n",
        "plt.figure(figsize=(10,2))\n",
        "for i in range(n_aug):\n",
        "    aug_x, _ = next(preview_gen)\n",
        "    plt.subplot(1, n_aug, i+1)\n",
        "    plt.imshow(aug_x[0])\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Augmentation Preview (random transforms)', y=0.95)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart shows different variations of the same image after applying transformations like rotation, zoom, and flips, demonstrating how data augmentation increases diversity in the training set to improve model generalization."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation significantly increases variability in the training data, which helps reduce overfitting by exposing the model to different orientations and lighting conditions."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By improving generalization, the model becomes more reliable in real-world scenarios, reducing misclassifications and improving diagnostic accuracy for brain tumor detection."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/final_trained_model.h5', compile=False)\n",
        "\n",
        "\n",
        "# ----------------- 2. Test Data Generator -----------------\n",
        "TEST_PATH = '/content/tumor_data/Tumour/test'  # Change path if needed\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ----------------- 3. Predictions -----------------\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# ----------------- 4. Classification Report -----------------\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "# ----------------- 5. Confusion Matrix -----------------\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - Brain Tumor Classification\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------- 6. Overall Accuracy -----------------\n",
        "accuracy = (y_pred == y_true).mean() * 100\n",
        "print(f\"Overall Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9RQhAGG1S_hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and plot class-wise accuracy\n",
        "def class_wise_accuracy(y_true, y_pred, class_labels):\n",
        "    accs = []\n",
        "    for i, cls in enumerate(class_labels):\n",
        "        idx = np.where(y_true == i)[0]\n",
        "        cls_acc = (y_pred[idx] == y_true[idx]).mean() if len(idx) else np.nan\n",
        "\n",
        "        accs.append(cls_acc * 100)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(class_labels, accs, color='blue')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Class-wise Accuracy')\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.ylim(0, 100)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return accs\n",
        "\n",
        "# ‚úÖ Call after predictions\n",
        "class_wise_accuracy(y_true, y_pred, class_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class-wise accuracy chart is critical because overall accuracy can hide weaknesses in specific categories. For medical applications like brain tumor detection, misclassification in one class (e.g., no tumor vs. glioma) can have severe consequences. This chart ensures transparency about how the model behaves for each class.\n",
        "\n"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart revealed that some classes, such as pituitary and meningioma, achieved higher accuracy, while others like glioma performed relatively lower. This indicates that the model might need more representative samples or targeted augmentation for certain classes."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focusing on improving accuracy for underperforming tumor types reduces diagnostic errors, leading to more reliable medical predictions. This can enhance trust in the system for clinical use and minimize risks associated with misdiagnosis, ultimately improving patient safety and healthcare outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Correlation Heatmap\n"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming y_pred_probs from model.predict(test_generator)\n",
        "# and class_labels already defined\n",
        "\n",
        "# Create DataFrame of probabilities\n",
        "probs_df = pd.DataFrame(y_pred_probs, columns=class_labels)\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = probs_df.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap of Predicted Class Probabilities')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shows relationships between classes based on model predictions. If two tumor classes have high correlation, the model often confuses them."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If glioma and meningioma show strong positive correlation, it explains misclassifications and indicates they share visual similarities."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# 1. Reduce prediction probabilities to 3 PCA components\n",
        "pca = PCA(n_components=3)\n",
        "reduced = pca.fit_transform(y_pred_probs)\n",
        "\n",
        "# 2. Create DataFrame for visualization\n",
        "df = pd.DataFrame(reduced, columns=['PC1', 'PC2', 'PC3'])\n",
        "df['Class'] = [class_labels[i] for i in test_generator.classes]\n",
        "\n",
        "# 3. Plot Pairplot\n",
        "sns.pairplot(df, hue='Class', vars=['PC1', 'PC2', 'PC3'], palette='husl')\n",
        "plt.suptitle(\"PCA Pairplot of Prediction Probabilities\", y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps visualize high-dimensional CNN features in 2D/3D space for class separability."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observed overlapping clusters between glioma and meningioma, explaining why these classes confused the model."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis testing was not included in this project because the primary goal was to build a predictive model for accurate brain tumor classification, not to infer population parameters or validate statistical assumptions. The evaluation focused on performance metrics such as accuracy, precision, recall, F1-score, and confusion matrix, which are more relevant for deep learning models. However, hypothesis testing could be explored in future work to statistically compare different models and validate performance improvements.\n"
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional preprocessing steps like handling missing values, outliers, or categorical encoding are not required in image-based projects. Since the dataset is composed of labeled images organized in folders, the model learns directly from visual patterns. Preprocessing here refers to image resizing, normalization, and augmentation instead of tabular data cleaning.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the data needs to be transformed using augmentation techniques like rotation, flipping, zoom, and brightness adjustments. These transformations help simulate real-world variability in MRI scans and prevent the model from overfitting to limited patterns. By artificially increasing the diversity of the training data, the model learns to generalize better on unseen images."
      ],
      "metadata": {
        "id": "3ZU_vjlZnyql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image augmentation applied only to training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization generator (applied to ALL splits: train, valid, test)\n",
        "scaling_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used min-max scaling by setting rescale=1./255 in the ImageDataGenerator, which converts pixel values from the range [0, 255] to [0, 1]. This normalization helps the model train faster, reduces numerical instability, and ensures consistency across images. It‚Äôs a standard and effective scaling method for deep learning tasks involving image data.\n",
        "\n"
      ],
      "metadata": {
        "id": "AWwctPpZ7tj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, dimensionality reduction is needed in this project. The original MRI images are 640√ó640 pixels, which are large and computationally expensive to process. By resizing them to 224√ó224 pixels, we reduce memory usage and training time while still preserving the essential features needed for tumor classification. This size is also compatible with most pretrained CNN architectures like ResNet and VGG."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the dataset paths if they were lost\n",
        "train_path = '/content/tumor_data/Tumour/train'\n",
        "valid_path = '/content/tumor_data/Tumour/valid'\n",
        "test_path  = '/content/tumor_data/Tumour/test'\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),  # This is dimensionality reduction!\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We used **image resizing** as the dimensionality reduction technique by setting the target size to **224√ó224 pixels**. This was done using the `target_size` parameter in `ImageDataGenerator`. It helps reduce computational load while keeping important visual features intact for accurate classification.\n"
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, additional data splitting is not needed.\n",
        "\n",
        "The dataset already comes pre-divided into three folders: train, valid, and test. Each folder contains images organized by class, which makes it ready to be directly used with ImageDataGenerator without any manual splitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset shows a moderate class imbalance, with glioma having the highest number of images and no_tumor the least. To address this, we used data augmentation during training to increase the diversity of underrepresented classes. Additionally, we will apply class_weight during model training to ensure that the model doesn't become biased toward the majority classes.\n"
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Get class indices from the train_generator\n",
        "class_indices = train_generator.class_indices  # e.g., {'glioma': 0, 'meningioma': 1, ...}\n",
        "class_labels = list(class_indices.values())   # [0, 1, 2, 3]\n",
        "\n",
        "# Compute weights\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "\n",
        "# Convert to dictionary format expected by Keras\n",
        "class_weights = dict(zip(class_labels, class_weights_array))\n",
        "\n",
        "print(\"üìä Computed Class Weights:\", class_weights)\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Class weighting technique was used to handle the moderate imbalance in the dataset. This approach assigns higher importance (loss penalty) to underrepresented classes during training. It ensures the model treats all classes fairly, even when some have fewer images, improving overall classification performance and reducing bias.\n",
        "\n"
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, GlobalAveragePooling2D,\n",
        "    Dense, Dropout, BatchNormalization\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Paths / Config\n",
        "TRAIN_PATH = '/content/tumor_data/Tumour/train'\n",
        "VALID_PATH = '/content/tumor_data/Tumour/valid'\n",
        "\n",
        "BEST_MODEL_PATH = '/content/drive/MyDrive/cnn_last_epoch.h5'\n",
        "LAST_MODEL_PATH = '/content/drive/MyDrive/improved_cnn_best_valacc.h5'\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# Skip switch: set True to skip retraining\n",
        "SKIP_TRAINING = True   # <-- flip to False to train\n",
        "\n",
        "\n",
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=(0.8, 1.2),\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    VALID_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# Class Weights (imbalance handling)\n",
        "class_weights_arr = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_arr))\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "\n",
        "# Build CNN\n",
        "def build_model():\n",
        "    return Sequential([\n",
        "        # Block 1\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same',\n",
        "               kernel_initializer=HeNormal(), input_shape=(224, 224, 3)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', kernel_initializer=HeNormal()),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        # Block 2\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=HeNormal()),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=HeNormal()),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        # Block 3\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=HeNormal()),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Head\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(128, activation='relu', kernel_initializer=HeNormal()),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')  # 4 classes\n",
        "    ])\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# Compile\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=2e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=6,\n",
        "    restore_best_weights=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    BEST_MODEL_PATH,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Train (guarded skip)\n",
        "if SKIP_TRAINING:\n",
        "    if os.path.exists(BEST_MODEL_PATH):\n",
        "        print(\"‚è© Skipping training (already trained, best model exists at: \"\n",
        "              f\"{BEST_MODEL_PATH}).\")\n",
        "    else:\n",
        "        print(\"‚ö† SKIP_TRAINING=True but no saved model found. \"\n",
        "              \"Set SKIP_TRAINING=False to train.\")\n",
        "else:\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=valid_generator,\n",
        "        epochs=EPOCHS,\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "    # Save last epoch model\n",
        "    model.save(LAST_MODEL_PATH)\n",
        "    print(\"‚úÖ Training complete.\")\n",
        "    print(\"Saved best (val_acc) to:\", BEST_MODEL_PATH)\n",
        "    print(\"Saved last epoch model to:\", LAST_MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Built a Custom Convolutional Neural Network (CNN) from scratch using Keras. The model has 3 convolutional blocks for feature extraction, followed by dense layers for classification. It was trained to classify brain MRI images into four categories: glioma, meningioma, pituitary tumor and no tumor.\n",
        "\n"
      ],
      "metadata": {
        "id": "_HjMaIFQ4Amy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Paths\n",
        "model_path = '/content/drive/MyDrive/cnn_last_epoch.h5'\n",
        "test_path = '/content/tumor_data/Tumour/test'\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Load Model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Test Data Generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nüìä CNN Model Classification Report:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title(\"Confusion Matrix - CNN Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy & Loss Chart\n",
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\n‚úÖ Overall Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used **manual tuning combined with callbacks like EarlyStopping and ReduceLROnPlateau** to optimize learning rate and prevent overfitting. This approach was chosen because it‚Äôs faster and more practical for large CNN models compared to exhaustive automated searches.\n"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Config\n",
        "train_path = '/content/tumor_data/Tumour/train'\n",
        "valid_path = '/content/tumor_data/Tumour/valid'\n",
        "\n",
        "BEST_MODEL_PATH = '/content/tuned_cnn_best.h5'\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/tuned_cnn_final.h5'\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "\n",
        "# Flip to False to retrain\n",
        "SKIP_TRAINING = True\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "valid_gen = valid_datagen.flow_from_directory(\n",
        "    valid_path, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Model Architecture\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint(\n",
        "    BEST_MODEL_PATH,\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.3,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train (skip-aware)\n",
        "if SKIP_TRAINING:\n",
        "    if os.path.exists(FINAL_MODEL_PATH) or os.path.exists(BEST_MODEL_PATH):\n",
        "        print(\"‚è© Skipping training (already trained; model saved).\")\n",
        "    else:\n",
        "        print(\"‚ö† SKIP_TRAINING=True but no saved model found. Set SKIP_TRAINING=False to train.\")\n",
        "else:\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=valid_gen,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint, early_stop, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "    # Save final model\n",
        "    model.save(FINAL_MODEL_PATH)\n",
        "    print(\"‚úÖ Model saved as\", FINAL_MODEL_PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ry2aip_bNRzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ‚úÖ CNN Evaluation (Test Only)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 1. Paths & Config\n",
        "BEST_MODEL_PATH = '/content/drive/MyDrive/tuned_cnn_final.h5'\n",
        "TEST_PATH = '/content/tumor_data/Tumour/test'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "# 2. Load Model\n",
        "print(\"Loading best saved model...\")\n",
        "model = load_model(BEST_MODEL_PATH)\n",
        "\n",
        "\n",
        "# 3. Prepare Test Data Generator\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_gen = datagen.flow_from_directory(\n",
        "    TEST_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# 4. Evaluation on Test Set\n",
        "y_true = test_gen.classes\n",
        "class_labels = list(test_gen.class_indices.keys())\n",
        "\n",
        "print(\"\\nPredicting on Test set...\")\n",
        "probs = model.predict(test_gen, verbose=1)\n",
        "y_pred = np.argmax(probs, axis=1)\n",
        "\n",
        "accuracy = (y_true == y_pred).mean()\n",
        "print(f\"\\n‚úÖ Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - Test Set\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PbqULTRzST0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Imports & Setup\n",
        "import os\n",
        "from collections import Counter\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Paths & Config\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "\n",
        "train_path = '/content/tumor_data/Tumour/train'\n",
        "valid_path = '/content/tumor_data/Tumour/valid'\n",
        "\n",
        "# Paths for saving\n",
        "BEST_CHECKPOINT_PATH = '/content/drive/MyDrive/best_model.h5'   # checkpoint\n",
        "FINAL_MODEL_PATH     = '/content/drive/MyDrive/final_trained_model.h5'  # last-epoch save\n",
        "\n",
        "# Skip switch: set True to avoid retraining\n",
        "SKIP_TRAINING = True   # <-- flip to False to retrain\n",
        "\n",
        "\n",
        "# Data Generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Class Weights\n",
        "class_counts = Counter(train_generator.classes)\n",
        "total = sum(class_counts.values())\n",
        "class_weights = {i: total / (len(class_counts) * count) for i, count in class_counts.items()}\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "#  Skip\n",
        "if SKIP_TRAINING:\n",
        "    if os.path.exists(FINAL_MODEL_PATH):\n",
        "        print(f\"‚è© Skipping training. Loading model from: {FINAL_MODEL_PATH}\")\n",
        "        model = load_model(FINAL_MODEL_PATH)\n",
        "    else:\n",
        "        print(f\"‚ö† SKIP_TRAINING=True but model not found at {FINAL_MODEL_PATH}.\")\n",
        "        print(\"‚û° Please set SKIP_TRAINING=False to train the model.\")\n",
        "        raise SystemExit(\"Stopping execution to avoid retraining.\")\n",
        "else:\n",
        "    print(\"‚úÖ Training started...\")\n",
        "\n",
        "    # Build model\n",
        "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "    # Freeze first 100 layers\n",
        "    for layer in base_model.layers[:100]:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[100:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # Custom classification head\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    # Compile\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
        "    checkpoint = ModelCheckpoint(BEST_CHECKPOINT_PATH, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=valid_generator,\n",
        "        callbacks=[early_stop, checkpoint],\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save final model\n",
        "    model.save(FINAL_MODEL_PATH)\n",
        "    print(f\"‚úÖ Training complete. Best checkpoint: {BEST_CHECKPOINT_PATH}, Final model: {FINAL_MODEL_PATH}\")\n"
      ],
      "metadata": {
        "id": "Z-6IF4k49Gb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used ResNet50, a deep convolutional neural network pretrained on ImageNet, to classify brain MRI images into four categories: glioma, meningioma, pituitary, and no_tumor. ResNet50‚Äôs architecture uses residual connections to train deeper networks efficiently, making it ideal for complex image classification tasks."
      ],
      "metadata": {
        "id": "KrnKwbdosS48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load the trained ResNet50 model\n",
        "model = load_model('/content/drive/MyDrive/best_model.h5')\n",
        "\n",
        "# 2. Define paths\n",
        "test_path = '/content/tumor_data/Tumour/test'\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# 3. Preprocess test images\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "# 4. Predict on test set\n",
        "y_pred_probs = model.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "\n",
        "# 5. Compute Overall Accuracy\n",
        "accuracy = np.mean(y_true == y_pred) * 100\n",
        "print(f\"\\n‚úÖ Overall Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# 6. Classification report\n",
        "print(\"\\nüìä Classification Report for ResNet50:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "# 7. Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(f\"ResNet50 - Confusion Matrix \")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n"
      ],
      "metadata": {
        "id": "9iODlK-1RBFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# ----------- CONFIG -----------\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "TRAIN_PATH = '/content/tumor_data/Tumour/train'\n",
        "VALID_PATH = '/content/tumor_data/Tumour/valid'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/best_model_finetuned.h5'  # checkpoint + final\n",
        "\n",
        "# Skip switch: set True to avoid retraining\n",
        "SKIP_TRAINING = True  # flip to False when you want to train again\n",
        "\n",
        "\n",
        "# DATA PREPROCESSING\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.15,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    VALID_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# CLASS WEIGHTS\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "\n",
        "# Skip or Train\n",
        "if SKIP_TRAINING:\n",
        "    if os.path.exists(MODEL_SAVE_PATH):\n",
        "        print(f\"‚è© Skipping training. Loading saved model from: {MODEL_SAVE_PATH}\")\n",
        "        model = load_model(MODEL_SAVE_PATH)\n",
        "    else:\n",
        "        print(f\"‚ö† SKIP_TRAINING=True but no saved model found at {MODEL_SAVE_PATH}.\")\n",
        "        print(\"Set SKIP_TRAINING=False to train.\")\n",
        "        raise SystemExit(\"Stopped to prevent unintended long training.\")\n",
        "else:\n",
        "    print(\"‚úÖ Starting fine-tuning...\")\n",
        "\n",
        "    # MODEL BUILDING\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "    # Unfreeze top 50% of layers\n",
        "    cutoff = int(len(base_model.layers) * 0.5)\n",
        "    for layer in base_model.layers[:cutoff]:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[cutoff:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "    # COMPILE\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # CALLBACKS\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True, verbose=1)\n",
        "    checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "    # TRAIN\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=valid_generator,\n",
        "        callbacks=[early_stop, checkpoint],\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Explicit final save (overwrites with final weights ‚Äî optional)\n",
        "    model.save(MODEL_SAVE_PATH)\n",
        "    print(f\"‚úÖ Training complete. Model saved to: {MODEL_SAVE_PATH}\")\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"final_trained_model.keras\")   # creates a .keras zip file\n",
        "\n",
        "model.export(\"final_trained_model_savedmodel\")   # folder\n",
        "# or explicit:\n",
        "# tf.saved_model.save(model, \"final_trained_model_savedmodel\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GIxV6pUCQC8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Paths\n",
        "CHECKPOINT_PATH = '/content/drive/MyDrive/best_model_finetuned.h5'   # weights after first 10 epochs\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/final_trained_model.h5'   # after resume (epoch 20)\n",
        "\n",
        "# Skip control\n",
        "SKIP_RESUME = True   # flip to False to continue training\n",
        "\n",
        "# Resume or Skip\n",
        "if SKIP_RESUME:\n",
        "    if os.path.exists(FINAL_MODEL_PATH):\n",
        "        print(f\"‚è© Skipping resume training (final model already saved). Loading {FINAL_MODEL_PATH} for evaluation.\")\n",
        "        model = load_model(FINAL_MODEL_PATH)\n",
        "    elif os.path.exists(CHECKPOINT_PATH):\n",
        "        print(f\"‚è© Skipping resume; using checkpoint at epoch 10: {CHECKPOINT_PATH}\")\n",
        "        model = load_model(CHECKPOINT_PATH)\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            \"Skip requested but no saved model found. \"\n",
        "            \"Set SKIP_RESUME=False to resume training.\"\n",
        "        )\n",
        "else:\n",
        "    # Load checkpoint from first training phase if needed\n",
        "    if 'model' not in globals():\n",
        "        if os.path.exists(CHECKPOINT_PATH):\n",
        "            print(f\"Loading checkpoint from: {CHECKPOINT_PATH}\")\n",
        "            model = load_model(CHECKPOINT_PATH)\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Checkpoint not found at {CHECKPOINT_PATH} and no model in memory.\")\n",
        "\n",
        "    # Callbacks for resume phase\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Resume Training\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=20,              # total target epochs\n",
        "        initial_epoch=10,       # resume from 10\n",
        "        validation_data=valid_generator,\n",
        "        callbacks=[early_stop, reduce_lr],\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save final trained model\n",
        "    model.save(FINAL_MODEL_PATH)\n",
        "    print(f\"‚úÖ Resume complete. Final model saved to: {FINAL_MODEL_PATH}\")\n"
      ],
      "metadata": {
        "id": "aZu31ss6gEkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I used **ReduceLROnPlateau** as the hyperparameter optimization technique. It dynamically reduces the learning rate when the validation loss plateaus, helping the model converge better and avoid overshooting minima. This improves fine-tuning efficiency and stabilizes training for better accuracy.\n"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load your trained model from Google Drive or local path\n",
        "model = load_model('/content/drive/MyDrive/final_trained_model.h5')  # or 'best_model.keras' if you used that format\n",
        "\n",
        "# Define test data path\n",
        "test_path = '/content/tumor_data/Tumour/test'\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# Create test data generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Important for matching predictions with labels\n",
        ")\n",
        "\n",
        "# Predict\n",
        "y_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_probs, axis=1)\n",
        "y_true = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# üìä Classification Report\n",
        "print(\"\\nüìà Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "# üîç Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# üìâ Plot Confusion Matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - Brain Tumor Classification\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ‚úÖ Overall Accuracy\n",
        "accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "print(f\"\\n‚úÖ Overall Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "AaEngAqkla0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Evaluation Metrics & Business Impact\n",
        "\n",
        "- **Accuracy**: Shows overall correctness. High accuracy builds trust but may be misleading with imbalanced classes.\n",
        "\n",
        "- **Precision**: Measures how many predicted tumor cases are actually correct. Helps reduce false alarms and unnecessary medical procedures.\n",
        "\n",
        "- **Recall**: Captures how many actual tumor cases the model detects. Crucial in healthcare ‚Äî missing a tumor can be fatal.\n",
        "\n",
        "- **F1-Score**: Balances precision and recall. Indicates a model that‚Äôs both reliable and safe for medical deployment.\n",
        "\n",
        "- **Confusion Matrix**: Reveals specific misclassifications. Helps improve the model for underperforming tumor types.\n",
        "\n",
        "###  Business Impact\n",
        "\n",
        "Using a ResNet50-based model improves diagnosis speed, reduces radiologist workload, and enhances early detection ‚Äî leading to better patient outcomes and increased operational efficiency.\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the **fine-tuned ResNet50 model** as the final prediction model. It leverages transfer learning from ImageNet, giving it a strong ability to extract complex features compared to custom CNNs. This model achieved better validation accuracy and generalization due to its deep architecture and fine-tuning strategy, making it the most reliable choice for brain tumor classification.\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used ResNet50, a deep convolutional neural network with 50 layers, based on residual learning. It introduces skip connections (residual blocks) to solve the vanishing gradient problem, making it effective for training very deep networks. In this project, the base ResNet50 was fine-tuned on brain tumor images, with a custom classification head for four classes: glioma, meningioma, pituitary, and no tumor.\n",
        "\n",
        "For feature importance, I used Grad-CAM (Gradient-weighted Class Activation Mapping). Grad-CAM highlights the regions in the image that most influenced the model‚Äôs prediction by computing the gradient of the output class with respect to the feature maps. This helps visualize which areas of the brain MRI contributed most to classifying a specific tumor type."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The .h5 format in Keras saves the complete model, including architecture, weights, and optimizer state, making it ready for direct inference and deployment. Unlike joblib or pickle, which are used for scikit-learn models, .h5 is the standard for TensorFlow/Keras. This format works seamlessly in deployment environments such as Flask, FastAPI, or Streamlit. Additionally, it can be easily converted to TensorFlow Lite or ONNX for optimized deployment."
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started this project by preprocessing and augmenting the MRI dataset to reduce overfitting and improve generalization. After experimenting with a custom CNN for baseline results, I moved to transfer learning using ResNet50, combined with class balancing, dropout, and regularization to enhance performance.\n",
        "\n",
        "The tuned ResNet50 achieved 84.15% validation accuracy, which was significantly better than the earlier models. I evaluated the model using precision, recall, F1-score, and confusion matrices to understand its strengths and weaknesses. To ensure reliability, I also applied Grad-CAM for explainability, confirming that predictions focused on tumor regions. The final model was saved as an H5 file, making it ready for deployment.\n",
        "\n",
        "Future improvements include adding more data, trying 3D CNN architectures, and validating the model on clinical datasets. This project shows how deep learning can be effectively applied to medical image classification while maintaining explainability and robustness.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Deep Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}